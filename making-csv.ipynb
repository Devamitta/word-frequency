{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_ods_reader import read_ods \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nid\n",
    "\n",
    "df_nid = pd.read_csv(\"../spreadsheets/nidh_bold.csv\", sep=\"\\t\", dtype= str)\n",
    "df_nid.fillna(\"\", inplace=True)\n",
    "\n",
    "df_nid['Pāli1'] = df_nid['Pāli1'].str.replace('\\d+', '')\n",
    "df_nid['Pāli1'] = df_nid['Pāli1'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare df_fr\n",
    "\n",
    "df_fr = read_ods(\"original-sources/frequent-words.ods\")\n",
    "df_fr.fillna(\"\", inplace=True)\n",
    "\n",
    "df_fr = df_fr.sort_values(by=['count'], ascending = False)\n",
    "\n",
    "# keep original\n",
    "df_fr_orig = df_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter adv\n",
    "test1 = df_fr['POS'] == \"ind\"\n",
    "test2 = df_fr['Grammar'] == \"time\"\n",
    "test3 = df_fr['Grammar'] == \"place\"\n",
    "test4 = df_fr['Grammar'] == \"interr\"\n",
    "\n",
    "filter = test1 & test2\n",
    "df_time = df_fr.loc[filter]\n",
    "\n",
    "filter = test1 & test3\n",
    "df_place = df_fr.loc[filter]\n",
    "\n",
    "filter = test1 & test4\n",
    "df_interr = df_fr.loc[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save adv of time\n",
    "df_time = df_time[['Pāli1', 'POS', 'Pattern', 'count']]\n",
    "\n",
    "df_time.to_csv(\"frequent-words/adv_time.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find words in niddhi\n",
    "\n",
    "test1 = df_nid['Pāli1'].isin(df_time['Pāli1'])\n",
    "test2 = df_nid['POS'].isin(df_time['POS'])\n",
    "\n",
    "logix = test1 & test2\n",
    "\n",
    "df_time_dpd = df_nid[logix]\n",
    "\n",
    "# merge frequency column\n",
    "df_time_dpd = pd.merge(df_time_dpd, df_time, how='left')\n",
    "\n",
    "# cleaning ex2\n",
    "df_time_dpd['Source 2'] = \"\"\n",
    "df_time_dpd['Sutta2'] = \"\"\n",
    "df_time_dpd['Example 2'] = \"\"\n",
    "\n",
    "# adding feedback\n",
    "df_time_dpd.reset_index(drop=True, inplace=True)\n",
    "df_time_dpd['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform?usp=pp_url&entry.438735500=\"\"\" + df_time_dpd.Pāli1 + \"\"\"&entry.1433863141=Pāli Class Vocab\">Fix it here</a>.\"\"\"\n",
    "df_time_dpd['marks'] = \"\"\n",
    "\n",
    "# adding tag\n",
    "df_time_dpd['Tag'] = df_time_dpd['Pattern']\n",
    "df_time_dpd['Tag'] = df_time_dpd['Tag'].str.replace(' ', '-')\n",
    "\n",
    "# choosing order of columns\n",
    "df_time_dpd = df_time_dpd[['Pāli1', 'POS', 'Grammar', 'Derived from', 'Neg', 'Verb', 'Trans', 'Case', 'Meaning IN CONTEXT', 'Meaning in native language', 'Pāli Root', 'Base', 'Construction', 'Sanskrit', 'Sk Root', 'Source1', 'Sutta1', 'Example1', 'Source 2', 'Sutta2', 'Example 2', 'Stem', 'Pattern', 'count', 'Feedback', 'Tag', 'marks']]\n",
    "\n",
    "df_time_dpd.to_csv(\"frequent-words-dpd/adv_time_dpd.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find if not\n",
    "\n",
    "test1 = ~df_time['Pāli1'].isin(df_nid['Pāli1'])\n",
    "# test2 = ~df_time['Pattern'].isin(df_nid['Pattern'])\n",
    "\n",
    "logix = test1\n",
    "\n",
    "df_absent = df_time[logix]\n",
    "\n",
    "# df_absent = pd.concat([df_absent, df_time[logix]])\n",
    "# df_absent = df_absent df_class_1[logix]\n",
    "\n",
    "# adding feedback ?\n",
    "df_absent.reset_index(drop=True, inplace=True)\n",
    "df_absent['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform\">Fix it here</a>.\"\"\"\n",
    "\n",
    "\n",
    "df_absent.to_csv(f\"frequent-words-dpd/absent.csv\", sep=\"\\t\", index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save adv of place\n",
    "df_place = df_place[['Pāli1', 'POS', 'Pattern', 'count']]\n",
    "\n",
    "df_place.to_csv(\"frequent-words/adv_place.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find words in niddhi\n",
    "\n",
    "test1 = df_nid['Pāli1'].isin(df_place['Pāli1'])\n",
    "test2 = df_nid['POS'].isin(df_place['POS'])\n",
    "\n",
    "logix = test1 & test2\n",
    "\n",
    "df_place_dpd = df_nid[logix]\n",
    "\n",
    "# merge frequency column\n",
    "df_place_dpd = pd.merge(df_place_dpd, df_place, how='left')\n",
    "\n",
    "# cleaning ex2\n",
    "df_place_dpd['Source 2'] = \"\"\n",
    "df_place_dpd['Sutta2'] = \"\"\n",
    "df_place_dpd['Example 2'] = \"\"\n",
    "\n",
    "# adding feedback\n",
    "# df_place_dpd.reset_index(drop=True, inplace=True)\n",
    "df_place_dpd['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform?usp=pp_url&entry.438735500=\"\"\" + df_place_dpd.Pāli1 + \"\"\"&entry.1433863141=Pāli Class Vocab\">Fix it here</a>.\"\"\"\n",
    "df_place_dpd['marks'] = \"\"\n",
    "\n",
    "# adding tag\n",
    "df_place_dpd['Tag'] = df_place_dpd['Pattern']\n",
    "df_place_dpd['Tag'] = df_place_dpd['Tag'].str.replace(' ', '-')\n",
    "\n",
    "# choosing order of columns\n",
    "df_place_dpd = df_place_dpd[['Pāli1', 'POS', 'Grammar', 'Derived from', 'Neg', 'Verb', 'Trans', 'Case', 'Meaning IN CONTEXT', 'Meaning in native language', 'Pāli Root', 'Base', 'Construction', 'Sanskrit', 'Sk Root', 'Source1', 'Sutta1', 'Example1', 'Source 2', 'Sutta2', 'Example 2', 'Stem', 'Pattern', 'count', 'Feedback', 'Tag', 'marks']]\n",
    "\n",
    "df_place_dpd.to_csv(\"frequent-words-dpd/adv_place_dpd.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find if not\n",
    "\n",
    "test1 = ~df_place['Pāli1'].isin(df_nid['Pāli1'])\n",
    "# test2 = ~df_place['Pattern'].isin(df_nid['Pattern'])\n",
    "\n",
    "logix = test1\n",
    "\n",
    "# df_absent = pd.DataFrame()\n",
    "\n",
    "df_absent = pd.concat([df_absent, df_place[logix]])\n",
    "# df_absent = df_absent df_class_1[logix]\n",
    "\n",
    "# adding feedback ?\n",
    "# df_absent.reset_index(drop=True, inplace=True)\n",
    "df_absent['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform\">Fix it here</a>.\"\"\"\n",
    "\n",
    "\n",
    "df_absent.to_csv(f\"frequent-words-dpd/absent.csv\", sep=\"\\t\", index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save adv of interr\n",
    "df_interr = df_interr[['Pāli1', 'POS', 'Pattern', 'count']]\n",
    "\n",
    "df_interr.to_csv(\"frequent-words/adv_interr.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find words in niddhi\n",
    "\n",
    "test1 = df_nid['Pāli1'].isin(df_interr['Pāli1'])\n",
    "test2 = df_nid['POS'].isin(df_interr['POS'])\n",
    "\n",
    "logix = test1 & test2\n",
    "\n",
    "df_interr_dpd = df_nid[logix]\n",
    "\n",
    "# merge frequency column\n",
    "df_interr_dpd = pd.merge(df_interr_dpd, df_interr, how='left')\n",
    "\n",
    "# cleaning ex2\n",
    "df_interr_dpd['Source 2'] = \"\"\n",
    "df_interr_dpd['Sutta2'] = \"\"\n",
    "df_interr_dpd['Example 2'] = \"\"\n",
    "\n",
    "# adding feedback\n",
    "# df_interr_dpd.reset_index(drop=True, place=True)\n",
    "df_interr_dpd['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform?usp=pp_url&entry.438735500=\"\"\" + df_interr_dpd.Pāli1 + \"\"\"&entry.1433863141=Pāli Class Vocab\">Fix it here</a>.\"\"\"\n",
    "df_interr_dpd['marks'] = \"\"\n",
    "\n",
    "# adding tag\n",
    "df_interr_dpd['Tag'] = df_interr_dpd['Pattern']\n",
    "df_interr_dpd['Tag'] = df_interr_dpd['Tag'].str.replace(' ', '-')\n",
    "\n",
    "# choosing order of columns\n",
    "df_interr_dpd = df_interr_dpd[['Pāli1', 'POS', 'Grammar', 'Derived from', 'Neg', 'Verb', 'Trans', 'Case', 'Meaning IN CONTEXT', 'Meaning in native language', 'Pāli Root', 'Base', 'Construction', 'Sanskrit', 'Sk Root', 'Source1', 'Sutta1', 'Example1', 'Source 2', 'Sutta2', 'Example 2', 'Stem', 'Pattern', 'count', 'Feedback', 'Tag', 'marks']]\n",
    "\n",
    "df_interr_dpd.to_csv(\"frequent-words/adv_interr_dpd.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find if not\n",
    "\n",
    "test1 = ~df_interr['Pāli1'].isin(df_nid['Pāli1'])\n",
    "# test2 = ~df_interr['Pattern'].isin(df_nid['Pattern'])\n",
    "\n",
    "logix = test1\n",
    "\n",
    "# df_absent = pd.DataFrame()\n",
    "\n",
    "df_absent = pd.concat([df_absent, df_interr[logix]])\n",
    "# df_absent = df_absent df_class_1[logix]\n",
    "\n",
    "# adding feedback ?\n",
    "# df_absent.reset_index(drop=True, place=True)\n",
    "df_absent['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform\">Fix it here</a>.\"\"\"\n",
    "\n",
    "\n",
    "df_absent.to_csv(f\"frequent-words/absent.csv\", sep=\"\\t\", index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter not comp | comp vb | name\n",
    "test1 = df_fr_orig['Grammar'] != \"comp\"\n",
    "test2 = df_fr_orig['Grammar'] != \"comp vb\"\n",
    "# test3 = df_fr_orig['Grammar'] != \"name\"\n",
    "filter = test1 & test2\n",
    "df_fr_orig = df_fr_orig.loc[filter]\n",
    "\n",
    "# filter what is done\n",
    "df_fr = df_fr.head(1500)\n",
    "\n",
    "# filter not comp | comp vb | name\n",
    "test1 = df_fr['Grammar'] != \"comp\"\n",
    "test2 = df_fr['Grammar'] != \"comp vb\"\n",
    "# test3 = df_fr['Grammar'] != \"name\"\n",
    "filter = test1 & test2\n",
    "df_fr = df_fr.loc[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter masc\n",
    "\n",
    "test1 = df_fr['POS'] == \"masc\"\n",
    "test2 = df_fr['Pattern'] == \"a masc\"\n",
    "test3 = df_fr['Pattern'] == \"i masc\"\n",
    "test4 = df_fr['Pattern'] == \"ī masc\"\n",
    "test5 = df_fr['Pattern'] == \"u masc\"\n",
    "test6 = df_fr['Pattern'] == \"ar masc\"\n",
    "test7 = df_fr['Pattern'] == \"a masc east\"\n",
    "test8 = df_fr['Pattern'] == \"ū masc\"\n",
    "\n",
    "filter = test1 & test2\n",
    "df_a_masc = df_fr.loc[filter]\n",
    "\n",
    "filter = test1 & test7\n",
    "df_a_east_masc = df_fr.loc[filter]\n",
    "\n",
    "df_a_masc = pd.concat([df_a_masc, df_a_east_masc])\n",
    "df_a_masc = df_a_masc.sort_values(by=['count'], ascending = False)\n",
    "df_a_masc = df_a_masc.head(200)\n",
    "\n",
    "filter = test1 & test3\n",
    "df_i_masc = df_fr.loc[filter]\n",
    "\n",
    "test1 = df_fr_orig['POS'] == \"masc\"\n",
    "test4 = df_fr_orig['Pattern'] == \"ī masc\"\n",
    "filter = test1 & test4\n",
    "df_ii_masc = df_fr_orig.loc[filter]\n",
    "df_ii_masc = df_ii_masc.head(10)\n",
    "\n",
    "test1 = df_fr_orig['POS'] == \"masc\"\n",
    "test5 = df_fr_orig['Pattern'] == \"u masc\"\n",
    "filter = test1 & test5\n",
    "df_u_masc = df_fr_orig.loc[filter]\n",
    "df_u_masc = df_u_masc.head(12)\n",
    "\n",
    "test1 = df_fr_orig['POS'] == \"masc\"\n",
    "test6 = df_fr_orig['Pattern'] == \"ar masc\"\n",
    "filter = test1 & test6\n",
    "df_ar_masc = df_fr_orig.loc[filter]\n",
    "df_ar_masc = df_ar_masc.head(10)\n",
    "\n",
    "test1 = df_fr_orig['POS'] == \"masc\"\n",
    "test8 = df_fr_orig['Pattern'] == \"ū masc\"\n",
    "\n",
    "filter = test1 & test8\n",
    "df_uu_masc = df_fr_orig.loc[filter]\n",
    "df_uu_masc = df_uu_masc.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a_masc\n",
    "df_a_masc = df_a_masc[['Pāli1', 'POS', 'Pattern', 'count']]\n",
    "\n",
    "df_a_masc.to_csv(\"frequent-words/a_masc.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find words in niddhi\n",
    "\n",
    "test1 = df_nid['Pāli1'].isin(df_a_masc['Pāli1'])\n",
    "test2 = df_nid['Pattern'].isin(df_a_masc['Pattern'])\n",
    "\n",
    "logix = test1 & test2\n",
    "\n",
    "df_a_masc_dpd = df_nid[logix]\n",
    "\n",
    "# merge frequency column\n",
    "df_a_masc_dpd = pd.merge(df_a_masc_dpd, df_a_masc, how='left')\n",
    "\n",
    "# cleaning ex2\n",
    "df_a_masc_dpd['Source 2'] = \"\"\n",
    "df_a_masc_dpd['Sutta2'] = \"\"\n",
    "df_a_masc_dpd['Example 2'] = \"\"\n",
    "\n",
    "# adding feedback\n",
    "# df_a_masc_dpd.reset_index(drop=True, place=True)\n",
    "df_a_masc_dpd['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform?usp=pp_url&entry.438735500=\"\"\" + df_a_masc_dpd.Pāli1 + \"\"\"&entry.1433863141=Pāli Class Vocab\">Fix it here</a>.\"\"\"\n",
    "df_a_masc_dpd['marks'] = \"\"\n",
    "\n",
    "# adding tag\n",
    "df_a_masc_dpd['Tag'] = df_a_masc_dpd['Pattern']\n",
    "df_a_masc_dpd['Tag'] = df_a_masc_dpd['Tag'].str.replace(' ', '-')\n",
    "\n",
    "# choosing order of columns\n",
    "df_a_masc_dpd = df_a_masc_dpd[['Pāli1', 'POS', 'Grammar', 'Derived from', 'Neg', 'Verb', 'Trans', 'Case', 'Meaning IN CONTEXT', 'Meaning in native language', 'Pāli Root', 'Base', 'Construction', 'Sanskrit', 'Sk Root', 'Source1', 'Sutta1', 'Example1', 'Source 2', 'Sutta2', 'Example 2', 'Stem', 'Pattern', 'count', 'Feedback', 'Tag', 'marks']]\n",
    "\n",
    "df_a_masc_dpd.to_csv(\"frequent-words-dpd/a_masc_dpd.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find if not\n",
    "\n",
    "test1 = ~df_a_masc['Pāli1'].isin(df_nid['Pāli1'])\n",
    "# test2 = ~df_a_masc['Pattern'].isin(df_nid['Pattern'])\n",
    "\n",
    "logix = test1\n",
    "\n",
    "# df_absent = pd.DataFrame()\n",
    "\n",
    "df_absent = pd.concat([df_absent, df_a_masc[logix]])\n",
    "# df_absent = df_absent df_class_1[logix]\n",
    "\n",
    "# adding feedback ?\n",
    "# df_absent.reset_index(drop=True, place=True)\n",
    "df_absent['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform\">Fix it here</a>.\"\"\"\n",
    "\n",
    "\n",
    "df_absent.to_csv(f\"frequent-words/absent.csv\", sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter pr\n",
    "test1 = df_fr['POS'] == \"pr\"\n",
    "test2 = df_fr['Pattern'] == \"ati pr\"\n",
    "test3 = df_fr['Pattern'] == \"eti pr\"\n",
    "test4 = df_fr['Pattern'] == \"āti pr\"\n",
    "test5 = df_fr['Pattern'] == \"oti pr\"\n",
    "test6 = df_fr['Pattern'] == \"karoti pr\"\n",
    "test7 = df_fr['Pattern'] == \"hoti pr\"\n",
    "test8 = df_fr['Pattern'] == \"atthi pr\"\n",
    "test9 = df_fr['Pattern'] == \"natthi pr\"\n",
    "# irreg pr\n",
    "test10 = df_fr['Pattern'] == \"eti pr 2\"\n",
    "test11 = df_fr['Pattern'] == \"brūti pr\"\n",
    "test12 = df_fr['Pattern'] == \"dakkhati pr\"\n",
    "test13 = df_fr['Pattern'] == \"hanati pr\"\n",
    "test14 = df_fr['Pattern'] == \"kubbati pr\"\n",
    "\n",
    "filter = test1 & test2\n",
    "df_ati_pr = df_fr.loc[filter]\n",
    "df_ati_pr = df_ati_pr.head(100)\n",
    "\n",
    "filter = test1 & test3\n",
    "df_eti_pr = df_fr.loc[filter]\n",
    "\n",
    "filter = test1 & test4\n",
    "df_aati_pr = df_fr.loc[filter]\n",
    "\n",
    "filter = test1 & test5\n",
    "df_oti_pr = df_fr.loc[filter]\n",
    "\n",
    "filter = test1 & test6\n",
    "df_karoti = df_fr.loc[filter]\n",
    "\n",
    "df_oti_pr = pd.concat([df_oti_pr, df_karoti])\n",
    "df_oti_pr = df_oti_pr.sort_values(by=['count'], ascending = False)\n",
    "\n",
    "df_pr = pd.concat([df_ati_pr, df_eti_pr, df_aati_pr, df_oti_pr])\n",
    "\n",
    "test1 = df_pr['Grammar'] != \"pass\"\n",
    "test2 = df_pr['Grammar'] != \"caus\"\n",
    "filter = test1 & test2\n",
    "df_pr_act = df_pr.loc[filter]\n",
    "\n",
    "df_pr_act = df_pr_act.sort_values(by=['count'], ascending = False)\n",
    "\n",
    "filter = test1 & test7\n",
    "df_hoti = df_fr.loc[filter]\n",
    "\n",
    "filter = test1 & test8\n",
    "df_atthi = df_fr.loc[filter]\n",
    "\n",
    "filter = test1 & test9\n",
    "df_natthi = df_fr.loc[filter]\n",
    "\n",
    "df_be_pr = pd.concat([df_hoti, df_atthi, df_natthi])\n",
    "df_be_pr = df_be_pr.sort_values(by=['count'], ascending = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pr\n",
    "df_pr_act = df_pr_act[['Pāli1', 'POS', 'Pattern', 'count']]\n",
    "\n",
    "df_pr_act.to_csv(\"frequent-words/pr_act.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find words in niddhi\n",
    "\n",
    "test1 = df_nid['Pāli1'].isin(df_pr_act['Pāli1'])\n",
    "test2 = df_nid['Pattern'].isin(df_pr_act['Pattern'])\n",
    "\n",
    "logix = test1 & test2\n",
    "\n",
    "df_pr_act_dpd = df_nid[logix]\n",
    "\n",
    "# merge frequency column\n",
    "df_pr_act_dpd = pd.merge(df_pr_act_dpd, df_pr_act, how='left')\n",
    "\n",
    "# cleaning ex2\n",
    "df_pr_act_dpd['Source 2'] = \"\"\n",
    "df_pr_act_dpd['Sutta2'] = \"\"\n",
    "df_pr_act_dpd['Example 2'] = \"\"\n",
    "\n",
    "# adding feedback\n",
    "# df_pr_act_dpd.reset_index(drop=True, place=True)\n",
    "df_pr_act_dpd['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform?usp=pp_url&entry.438735500=\"\"\" + df_pr_act_dpd.Pāli1 + \"\"\"&entry.1433863141=Pāli Class Vocab\">Fix it here</a>.\"\"\"\n",
    "df_pr_act_dpd['marks'] = \"\"\n",
    "\n",
    "# adding tag\n",
    "df_pr_act_dpd['Tag'] = df_pr_act_dpd['Pattern']\n",
    "df_pr_act_dpd['Tag'] = df_pr_act_dpd['Tag'].str.replace(' ', '-')\n",
    "\n",
    "# choosing order of columns\n",
    "df_pr_act_dpd = df_pr_act_dpd[['Pāli1', 'POS', 'Grammar', 'Derived from', 'Neg', 'Verb', 'Trans', 'Case', 'Meaning IN CONTEXT', 'Meaning in native language', 'Pāli Root', 'Base', 'Construction', 'Sanskrit', 'Sk Root', 'Source1', 'Sutta1', 'Example1', 'Source 2', 'Sutta2', 'Example 2', 'Stem', 'Pattern', 'count', 'Feedback', 'Tag', 'marks']]\n",
    "\n",
    "df_pr_act_dpd.to_csv(\"frequent-words-dpd/pr_act_dpd.csv\", sep=\"\\t\", index=None)\n",
    "\n",
    "# find if not\n",
    "\n",
    "test1 = ~df_pr_act['Pāli1'].isin(df_nid['Pāli1'])\n",
    "# test2 = ~df_pr_act['Pattern'].isin(df_nid['Pattern'])\n",
    "\n",
    "logix = test1\n",
    "\n",
    "# df_absent = pd.DataFrame()\n",
    "\n",
    "df_absent = pd.concat([df_absent, df_pr_act[logix]])\n",
    "# df_absent = df_absent df_class_1[logix]\n",
    "\n",
    "# adding feedback ?\n",
    "# df_absent.reset_index(drop=True, place=True)\n",
    "df_absent['Feedback'] = f\"\"\"Spot a mistake? <a class=\"link\" href=\"https://docs.google.com/forms/d/e/1FAIpQLScNC5v2gQbBCM3giXfYIib9zrp-WMzwJuf_iVXEMX2re4BFFw/viewform\">Fix it here</a>.\"\"\"\n",
    "\n",
    "\n",
    "df_absent.to_csv(f\"frequent-words/absent.csv\", sep=\"\\t\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
